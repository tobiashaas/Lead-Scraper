version: '3.8'

# Production stack supports AWS Secrets Manager and HashiCorp Vault for secrets management.
# See docs/PRODUCTION.md#secrets-management for setup instructions and provider-specific guidance.

services:
  postgres:
    image: postgres:15-alpine
    container_name: kr-postgres-prod
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-kr_leads}
      POSTGRES_USER: ${POSTGRES_USER:-kr_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-kr_user} -d ${POSTGRES_DB:-kr_leads}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - kr-network

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: kr-prometheus-prod
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=60d'
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts:/etc/prometheus/alerts:ro
      - prometheus_prod_data:/prometheus
    restart: unless-stopped
    networks:
      - kr-network

  grafana:
    image: grafana/grafana:10.2.2
    container_name: kr-grafana-prod
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-change_me}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=https://grafana.localhost
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - grafana_prod_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - kr-network

  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: kr-alertmanager-prod
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=https://alertmanager.localhost'
    ports:
      - "127.0.0.1:9093:9093"
    environment:
      - ALERT_SMTP_HOST=${ALERT_SMTP_HOST}
      - ALERT_SMTP_PORT=${ALERT_SMTP_PORT}
      - ALERT_SMTP_USER=${ALERT_SMTP_USER}
      - ALERT_SMTP_PASSWORD=${ALERT_SMTP_PASSWORD}
      - ALERT_EMAIL_TO=${ALERT_EMAIL_TO}
      - ALERT_SLACK_WEBHOOK_URL=${ALERT_SLACK_WEBHOOK_URL}
    volumes:
      - ./monitoring/alertmanager/alertmanager.prod.yml:/etc/alertmanager/alertmanager.yml:ro
      - ./monitoring/alertmanager/templates:/etc/alertmanager/templates:ro
      - alertmanager_prod_data:/alertmanager
    depends_on:
      - prometheus
    restart: always
    networks:
      - kr-network

  redis:
    image: redis:7-alpine
    container_name: kr-redis-prod
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: always
    networks:
      - kr-network

  ollama:
    image: ollama/ollama:latest
    container_name: kr-ollama-prod
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: always
    networks:
      - kr-network
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  app-blue:
    image: ${IMAGE_REF:-ghcr.io/tobiashaas/lead-scraper:latest}
    container_name: kr-app-prod-blue
    working_dir: /app
    expose:
      - "8000"
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-kr_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-kr_leads}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - SECRETS_MANAGER=${SECRETS_MANAGER:-none}
      - AWS_REGION=${AWS_REGION:-eu-central-1}
      - AWS_SECRETS_NAME=${AWS_SECRETS_NAME:-kr-scraper/production}
      - VAULT_ADDR=${VAULT_ADDR:-}
      - VAULT_TOKEN=${VAULT_TOKEN:-}
      - VAULT_PATH=${VAULT_PATH:-secret/data/kr-scraper}
      - OLLAMA_HOST=http://ollama:11434
      - ENVIRONMENT=production
      - DEBUG=False
      - LOG_LEVEL=INFO
      - PROMETHEUS_ENABLED=True
      - PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus_multiproc
      - METRICS_INCLUDE_LABELS=True
      - METRICS_ENDPOINT_ENABLED=True
      # When deploying on AWS with IAM roles (EC2/ECS), do not define AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY.
      # The AWS SDK will automatically resolve credentials via the instance metadata service.
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./backups:/backups
    tmpfs:
      - /tmp/prometheus_multiproc
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: always
    networks:
      - kr-network
    labels:
      com.kr-scraper.environment: production
      com.kr-scraper.version: ${VERSION:-latest}
      com.kr-scraper.color: blue

  app-green:
    image: ${IMAGE_REF:-ghcr.io/tobiashaas/lead-scraper:latest}
    container_name: kr-app-prod-green
    working_dir: /app
    expose:
      - "8000"
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-kr_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-kr_leads}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - SECRETS_MANAGER=${SECRETS_MANAGER:-none}
      - AWS_REGION=${AWS_REGION:-eu-central-1}
      - AWS_SECRETS_NAME=${AWS_SECRETS_NAME:-kr-scraper/production}
      - VAULT_ADDR=${VAULT_ADDR:-}
      - VAULT_TOKEN=${VAULT_TOKEN:-}
      - VAULT_PATH=${VAULT_PATH:-secret/data/kr-scraper}
      - OLLAMA_HOST=http://ollama:11434
      - ENVIRONMENT=production
      - DEBUG=False
      - LOG_LEVEL=INFO
      - PROMETHEUS_ENABLED=True
      - PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus_multiproc
      - METRICS_INCLUDE_LABELS=True
      - METRICS_ENDPOINT_ENABLED=True
      # When deploying on AWS with IAM roles (EC2/ECS), do not define AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY.
      # The AWS SDK will automatically resolve credentials via the instance metadata service.
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    tmpfs:
      - /tmp/prometheus_multiproc
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: always
    networks:
      - kr-network
    labels:
      com.kr-scraper.environment: production
      com.kr-scraper.version: ${VERSION:-latest}
      com.kr-scraper.color: green

  worker-1:
    image: ${IMAGE_REF:-ghcr.io/tobiashaas/lead-scraper:latest}
    container_name: kr-worker-prod-1
    working_dir: /app
    command:
      - sh
      - -c
      - |
        python -c "from app.workers.queue import initialize_scheduled_jobs; initialize_scheduled_jobs()" || echo "Warning: Failed to initialize scheduled jobs"
        rq worker scraping maintenance --url redis://:${REDIS_PASSWORD}@redis:6379 --with-scheduler
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-kr_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-kr_leads}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - SECRETS_MANAGER=${SECRETS_MANAGER:-none}
      - AWS_REGION=${AWS_REGION:-eu-central-1}
      - AWS_SECRETS_NAME=${AWS_SECRETS_NAME:-kr-scraper/production}
      - VAULT_ADDR=${VAULT_ADDR:-}
      - VAULT_TOKEN=${VAULT_TOKEN:-}
      - VAULT_PATH=${VAULT_PATH:-secret/data/kr-scraper}
      - OLLAMA_HOST=http://ollama:11434
      - ENVIRONMENT=production
      - DEBUG=False
      - LOG_LEVEL=INFO
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./backups:/backups
    restart: always
    networks:
      - kr-network
    labels:
      com.kr-scraper.environment: production
      com.kr-scraper.service: worker
      com.kr-scraper.version: ${VERSION:-latest}

  worker-2:
    image: ${IMAGE_REF:-ghcr.io/tobiashaas/lead-scraper:latest}
    container_name: kr-worker-prod-2
    working_dir: /app
    command: rq worker scraping maintenance --url redis://:${REDIS_PASSWORD}@redis:6379
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-kr_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-kr_leads}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - SECRETS_MANAGER=${SECRETS_MANAGER:-none}
      - AWS_REGION=${AWS_REGION:-eu-central-1}
      - AWS_SECRETS_NAME=${AWS_SECRETS_NAME:-kr-scraper/production}
      - VAULT_ADDR=${VAULT_ADDR:-}
      - VAULT_TOKEN=${VAULT_TOKEN:-}
      - VAULT_PATH=${VAULT_PATH:-secret/data/kr-scraper}
      - OLLAMA_HOST=http://ollama:11434
      - ENVIRONMENT=production
      - DEBUG=False
      - LOG_LEVEL=INFO
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./backups:/backups
    restart: always
    networks:
      - kr-network
    labels:
      com.kr-scraper.environment: production
      com.kr-scraper.service: worker
      com.kr-scraper.version: ${VERSION:-latest}

  # Optional: self-hosted Vault service fronted by TLS proxy.
  # vault:
  #   image: hashicorp/vault:1.16
  #   container_name: kr-vault
  #   environment:
  #     VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_TOKEN:-changeme}
  #   ports:
  #     - "8200:8200"
  #   volumes:
  #     - ./vault:/vault/file
  #   command: vault server -config=/vault/config/vault.hcl
  #   restart: unless-stopped
  #   networks:
  #     - kr-network

  # Optional: secrets rotation sidecar triggering scripts/secrets/rotate_secrets.py every 90 days.
  # secrets-rotator:
  #   image: python:3.11-slim
  #   container_name: kr-secrets-rotator
  #   volumes:
  #     - ./scripts:/app/scripts:ro
  #   entrypoint: ["bash", "-lc", "while true; do python /app/scripts/secrets/rotate_secrets.py; sleep $((90*24*3600)); done"]
  #   environment:
  #     - SECRETS_MANAGER=${SECRETS_MANAGER:-none}
  #     - AWS_REGION=${AWS_REGION:-eu-central-1}
  #     - AWS_SECRETS_NAME=${AWS_SECRETS_NAME:-kr-scraper/production}
  #     - VAULT_ADDR=${VAULT_ADDR:-}
  #     - VAULT_TOKEN=${VAULT_TOKEN:-}
  #     - VAULT_PATH=${VAULT_PATH:-secret/data/kr-scraper}
  #   depends_on:
  #     - app-blue
  #   restart: unless-stopped
  #   networks:
  #     - kr-network

  # Nginx reverse proxy for blue-green traffic switching
  nginx:
    image: nginx:alpine
    container_name: kr-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx:/etc/nginx/conf.d:rw
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - app-blue
      - app-green
    restart: always
    networks:
      - kr-network

volumes:
  postgres_data:
  redis_data:
  ollama_data:
  prometheus_prod_data:
  grafana_prod_data:
  alertmanager_prod_data:

networks:
  kr-network:
    driver: bridge
