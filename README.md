# ğŸš€ KR-Lead-Scraper

Automatisiertes Lead-Scraping-System zur Extraktion von Unternehmensdaten aus Baden-WÃ¼rttemberg fÃ¼r IT/BÃ¼rotechnik/Dokumentenmanagement-Leads.

## ğŸ“‹ Ãœbersicht

KR-Lead-Scraper ist ein Python-basiertes Web-Scraping-Tool, das Ã¶ffentliche BranchenbÃ¼cher (11880, Gelbe Seiten, etc.) durchsucht und qualitativ hochwertige B2B-Leads fÃ¼r die Region Baden-WÃ¼rttemberg sammelt.

### âœ¨ Features

- ğŸ” **Multi-Source Scraping**: UnterstÃ¼tzung fÃ¼r mehrere BranchenbÃ¼cher
- ğŸ›¡ï¸ **Anti-Detection**: Tor Network Integration + Playwright Stealth Mode
- ğŸ¤– **AI-Powered**: Named Entity Recognition & Lead Scoring (geplant)
- ğŸ“Š **Data Quality**: Automatische Validierung, Deduplizierung & Normalisierung
- ğŸ”„ **Rate Limiting**: Intelligentes Request-Management mit Redis
- ğŸ³ **Docker Ready**: Einfaches Setup mit Docker Compose
- ğŸ“ˆ **REST API**: FastAPI fÃ¼r einfachen Datenzugriff

## ğŸ—ï¸ Architektur

```
KR-Lead-Scraper/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ scrapers/          # Scraper-Implementierungen
â”‚   â”œâ”€â”€ database/          # SQLAlchemy Models & Migrations
â”‚   â”œâ”€â”€ api/               # FastAPI Endpoints
â”‚   â”œâ”€â”€ utils/             # Proxy Manager, Rate Limiter, etc.
â”‚   â”œâ”€â”€ processors/        # Data Cleaning & Validation
â”‚   â”œâ”€â”€ ai/                # NER & Scoring (spÃ¤ter)
â”‚   â””â”€â”€ core/              # Configuration Management
â”œâ”€â”€ tests/                 # Unit & Integration Tests
â”œâ”€â”€ docs/                  # Dokumentation
â”œâ”€â”€ data/                  # Exports & Temp Files
â”œâ”€â”€ logs/                  # Log Files
â””â”€â”€ config/                # Config Files
```

## ğŸš€ Quick Start

### Voraussetzungen

- **Python 3.11+**
- **Docker & Docker Compose**
- **Tor** (fÃ¼r AnonymitÃ¤t)
- **Git**

### Installation

1. **Repository klonen**
   ```bash
   git clone https://github.com/Kunze-Ritter/KR-Lead-Scraper.git
   cd KR-Lead-Scraper
   ```

2. **Virtual Environment erstellen**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # venv\Scripts\activate    # Windows
   ```

3. **Dependencies installieren**
   ```bash
   pip install -r requirements.txt
   playwright install chromium
   ```

4. **Tor installieren & starten**
   ```bash
   # macOS
   brew install tor
   tor
   
   # Linux
   sudo apt install tor
   sudo systemctl start tor
   ```

5. **Environment Variables konfigurieren**
   ```bash
   cp .env.example .env
   # .env bearbeiten und PasswÃ¶rter anpassen
   ```

6. **Docker Services starten**
   ```bash
   docker-compose up -d
   ```

7. **Database Migrations ausfÃ¼hren** (spÃ¤ter)
   ```bash
   alembic upgrade head
   ```

## ğŸ”§ Konfiguration

### Tor Setup (Optional aber empfohlen)

FÃ¼r IP-Rotation Tor Control Port aktivieren:

```bash
# /etc/tor/torrc oder /usr/local/etc/tor/torrc bearbeiten:
ControlPort 9051
HashedControlPassword <generiertes_passwort>

# Passwort generieren:
tor --hash-password "your_password"
```

### Environment Variables

Wichtigste Einstellungen in `.env`:

```bash
# Tor aktivieren/deaktivieren
TOR_ENABLED=True

# Scraping Delays (in Sekunden)
SCRAPING_DELAY_MIN=3
SCRAPING_DELAY_MAX=8

# Rate Limiting
RATE_LIMIT_REQUESTS=10
RATE_LIMIT_WINDOW=60
```

## ğŸ“– Verwendung

### API starten (spÃ¤ter)

```bash
uvicorn app.main:app --reload
```

API verfÃ¼gbar unter: `http://localhost:8000`
Docs verfÃ¼gbar unter: `http://localhost:8000/docs`

### Scraping Job starten (Beispiel - spÃ¤ter)

```python
from app.scrapers.eleven_eighty import ElevenEightyScaper

scraper = ElevenEightyScaper()
results = await scraper.scrape(
    city="Stuttgart",
    industry="IT-Service"
)
```

## ğŸ§ª Testing

```bash
# Alle Tests ausfÃ¼hren
pytest

# Mit Coverage Report
pytest --cov=app --cov-report=html

# Nur Unit Tests
pytest tests/unit/

# Nur Integration Tests
pytest tests/integration/
```

## ğŸ“Š Technologie-Stack

- **Backend**: Python 3.11+, FastAPI, SQLAlchemy
- **Database**: PostgreSQL 15
- **Cache**: Redis 7
- **Scraping**: Playwright, BeautifulSoup4, httpx
- **AnonymitÃ¤t**: Tor Network (stem, pysocks)
- **Data Processing**: fuzzywuzzy, email-validator, phonenumbers
- **AI/NLP**: spaCy (geplant)
- **Testing**: pytest, pytest-asyncio
- **DevOps**: Docker, Docker Compose

## ğŸ—ºï¸ Roadmap

### Phase 1: MVP (4-6 Wochen) âœ… In Progress
- [x] Projektstruktur & Setup
- [x] Docker Compose Environment
- [ ] BaseScraper Framework
- [ ] 11880 Scraper
- [ ] Basis ETL Pipeline

### Phase 2: Erweiterung (4-6 Wochen)
- [ ] Gelbe Seiten Scraper
- [ ] Data Validation & Cleaning
- [ ] Deduplizierung
- [ ] FastAPI Endpoints

### Phase 3: AI & Automation (4-6 Wochen)
- [ ] Named Entity Recognition
- [ ] Lead Scoring
- [ ] Automatische Scraping-Jobs
- [ ] SmartWe Integration

### Phase 4: Production (2-4 Wochen)
- [ ] Testing & Bug Fixes
- [ ] Monitoring & Logging
- [ ] VPS Deployment
- [ ] Dokumentation

## âš–ï¸ Rechtliche Hinweise

**WICHTIG**: Dieses Tool scraped Ã¶ffentlich zugÃ¤ngliche Daten aus BranchenbÃ¼chern.

- âœ… **Erlaubt**: Ã–ffentliche BranchenbÃ¼cher (11880, Gelbe Seiten)
- âš ï¸ **Vorsicht**: robots.txt beachten, Rate Limiting einhalten
- âŒ **Verboten**: LinkedIn/Xing Scraping (ToS-VerstoÃŸ)

**Empfehlung**: 
- Langsames Scraping (3-8 Sekunden Delay)
- Tor/VPN fÃ¼r AnonymitÃ¤t
- Bei Unsicherheit rechtliche Beratung einholen

## ğŸ¤ Contributing

Contributions sind willkommen! Bitte:

1. Fork das Repository
2. Feature Branch erstellen (`git checkout -b feature/AmazingFeature`)
3. Ã„nderungen committen (`git commit -m 'Add AmazingFeature'`)
4. Branch pushen (`git push origin feature/AmazingFeature`)
5. Pull Request Ã¶ffnen

## ğŸ“ License

Dieses Projekt ist fÃ¼r interne Nutzung bei Kunze & Ritter vorgesehen.

## ğŸ“§ Kontakt

**Kunze & Ritter GmbH**
- Website: [kunze-ritter.de](https://kunze-ritter.de)
- GitHub: [@Kunze-Ritter](https://github.com/Kunze-Ritter)

## ğŸ™ Acknowledgments

- [Playwright](https://playwright.dev/) - Browser Automation
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Web Framework
- [Tor Project](https://www.torproject.org/) - Anonymity Network
- [spaCy](https://spacy.io/) - NLP Library

---

**Status**: ğŸš§ In Development - Phase 1 (MVP)

**Ziel**: 10.000+ qualitativ hochwertige Leads/Monat aus Baden-WÃ¼rttemberg
