#!/bin/bash
# Setup Script f√ºr Ollama Models
# L√§dt die wichtigsten Models f√ºr Lead-Scraping

set -e

echo "üöÄ KR-Lead-Scraper - Ollama Setup"
echo "=================================="
echo ""

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "‚ùå Ollama ist nicht erreichbar auf localhost:11434"
    echo "   Starte Docker Container: docker-compose up -d ollama"
    exit 1
fi

echo "‚úÖ Ollama ist erreichbar"
echo ""

# Function to pull model
pull_model() {
    local model=$1
    local description=$2

    echo "üì• Lade Model: $model"
    echo "   $description"

    if ollama pull "$model"; then
        echo "‚úÖ $model erfolgreich geladen"
    else
        echo "‚ö†Ô∏è  Fehler beim Laden von $model"
    fi
    echo ""
}

# Pull Models
echo "Lade empfohlene Models..."
echo ""

# Fast & Efficient (Default)
pull_model "llama3.2" "Schnell, gut f√ºr Extraktion (3B)"

# Better Quality
pull_model "mistral" "Bessere Qualit√§t f√ºr komplexe Texte (7B)"

# Specialized for Business Data
pull_model "qwen2.5:7b" "Spezialisiert f√ºr Business-Daten (7B)"

echo "=================================="
echo "‚úÖ Setup abgeschlossen!"
echo ""
echo "Verf√ºgbare Models:"
ollama list
echo ""
echo "üí° Tipp: √Ñndere das Model in .env:"
echo "   OLLAMA_MODEL=llama3.2  # oder mistral, qwen2.5"
echo ""
